---
title: "wrangling"
output:
  html_document:
    toc: true
    toc_depth: 2
  
date: "`r Sys.Date()`"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo=TRUE)
library(tidyverse)
library(readxl)
library(lubridate)
source("src/wrangling_functions.R") # store your functions somewhere to load

```

# Overview
Introduce what you're doing here

# Workflow

## Import data

```{R}
# Read files in directory
files <- dir("data", pattern = "*.xlsx")

# Import files
data <- tibble(filename = files)%>%
  mutate(file_contents = map(
    filename,
    ~read_excel(file.path("data/", .))
  ))

# Unnest and tidy columns
data2 <- unnest(data, cols = c(file_contents)) %>%
  rename_with(text_normalisation)%>% # applying string processing function
  separate(filename, c("drop","report_date"), sep = '_')%>% # example of how to extract metadata from filename
  mutate(report_date = str_remove_all(report_date, ".xlsx"))

```
## Validate data
not looked into yet, probably something with map_dfr(data, class) and comparing to a lookup.  Or keep looped option.

## Process data
```{r}

processed_data <- data %>%
  select(any_of(columns_of_interest)) %>% # keep only columns you want (also filter sites, data etc here)
  mutate(report_date = ymd(report_date))%>% # convert column types
  pivot_longer(-c(report_date, site, day_of_first_auth_date), names_to = 'indicator', values_to = 'value') # lengthen data

```

## Export data
```{r}
# Get current date
current_date <- format(Sys.Date(), "%Y-%m-%d")

# Write combined dataset to a new Excel file
write_xlsx(combined_data2, paste0("output/", "combined_dataset2_", processed_data, ".xlsx"))

```
